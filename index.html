<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>StatsHAL</title>
<script src="https://unpkg.com/compromise"></script>
<script src="https://cdn.jsdelivr.net/npm/stopword/dist/stopword.umd.min.js"></script>
<script src="assets/js/d3.v4.min.js"></script>
<script src="assets/js/wordstream.js"></script>
<style>
    #canvas{
        height: 1000px;
        width: 1000px;
    }
</style>
</head>
<body>
    <div id="canvas"></div>    
<script>
    const config = {
        topWord: 40,
        minFont: 12,
        maxFont: 25,
        tickFont: 12,
        legendFont: 12,
        curve: d3.curveMonotoneX
    };
    let dataForVis = [], words=[], svg = d3.select("#canvas").append('svg').attr("id", "mainSVG");
    d3.select("#canvas").style("max-width", window.innerWidth + "px");

    let uri = "https://api.archives-ouvertes.fr/search/?q=authIdHal_s:samuel-szoniecky&rows=100&fl=keyword_s,title_s,docid,uri_s,producedDate_s,publicationDate_s";
    d3.json(uri,data=>{
        console.log(data);
        /*
        d3.select('#rows').selectAll('p').data(rs.response.docs).enter()
        .append('p').html(r=>{
            return '"'+r.title_s[0]+'";'+r.producedDate_s.split('-')[0];
        });
        */
       dataForVis = getDataForVis(data.response.docs);
        svg.attr("width", Math.max(120 * dataForVis.length, 1200))
        svg.attr("height", 200 * Object.keys(dataForVis[0].words).length);
        wordstream(svg, dataForVis, config);


    });
    function getDataForVis(data){
        dataForVis=[];
        let g = d3.nest()
            .key(function(d){
                return d.producedDate_s.split('-')[0];
            })
            .entries(data);
        //let g = d3.group(data, d => d.producedDate_s.split('-')[0])
        g.forEach(date=>{
            let o = {'date':date.key,'words':{'keyword':[],'title':[]},'docs':[]};
            date.values.forEach(d=>{
                o.docs.push(d.docid);                            
                if(o.keyword_s) o.keyword_s.forEach(kw=>setWord(kw,o,date,'keyword'));
                let ekw = nlp(cleanText(d.title_s.join())),
                terms = ekw.terms().json();
                terms.forEach(t=>{
                    if(t.text.length>3)setWord(t.text,o,date,'title');
                })
            })
            dataForVis.push(o)
        })
        return dataForVis;
    }
    function cleanText(t){
        t = t.replace(/.'/, '')
        .replace(/.’/, '')
        .replace(/.'/, '')
        .replace(/.’/, '')               
        .replace(/[.,\/#!,«»$%\^&\*;:{}=\-_`~()]/mg," ")
        .replace(/\.\s+|\n|\r|\0/mg,' ')
        .replace(/\s-+\s/mg,' ')
        .replace(/[©|]\s?/mg,' ')
        .replace(/[!(–?$”“…]/mg,' ')
        .replace(/\s{2,}|^\s/mg,' ');
        t = sw.removeStopwords(t.split(' '),sw.fra);
        t = sw.removeStopwords(t,sw.eng);
        
        return t.join(' ');
    }

    function setWord(w,o,k,t){
        let fi, aw = o.words[t].filter(d=>d.text==w);
        if(aw.length==0){
            fi = words.findIndex(d=>d==w);
            if(fi<0){
                words.push(w);
                fi = words.length-1;
            }
            o.words[t].push({frequency: 1,id: k+"w_"+fi,text:w,topic:t})
        }else
            aw[0].frequency++;
    }
</script>
    
</body>
</html>